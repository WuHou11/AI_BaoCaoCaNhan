# BÃ i táº­p CÃ¡ nhÃ¢n AI
## BÃ¹i Quá»‘c Háº­u-23110211
##    Giá»›i thiá»‡u bÃ i toÃ¡n 8-puzzle
BÃ i toÃ¡n 8-puzzle lÃ  má»™t bÃ i toÃ¡n kinh Ä‘iá»ƒn trong trÃ­ tuá»‡ nhÃ¢n táº¡o vÃ  thuáº­t toÃ¡n tÃ¬m kiáº¿m. BÃ i toÃ¡n gá»“m má»™t báº£ng 3x3 chá»©a 8 Ã´ sá»‘ tá»« 1 Ä‘áº¿n 8 vÃ  má»™t Ã´ trá»‘ng (kÃ½ hiá»‡u lÃ  0 hoáº·c Ã´ rá»—ng).CÃ¡c Ã´ cÃ³ thá»ƒ di chuyá»ƒn lÃªn, xuá»‘ng, trÃ¡i, pháº£i vÃ o vá»‹ trÃ­ Ã´ trá»‘ng vá»›i má»¥c tiÃªu lÃ  Ä‘Æ°a báº£ng tá»« tráº¡ng thÃ¡i ban Ä‘áº§u vá» tráº¡ng thÃ¡i Ä‘Ã­ch.
### 1. Má»¥c tiÃªu: 
Trong Ä‘á»“ Ã¡n cÃ¡ nhÃ¢n nÃ y, má»¥c tiÃªu chÃ­nh lÃ  xÃ¢y dá»±ng má»™t chÆ°Æ¡ng trÃ¬nh Ä‘á»ƒ giáº£i quyáº¿t bÃ i toÃ¡n 8-puzzle. Äá»“ Ã¡n táº­p trung vÃ o viá»‡c nghiÃªn cá»©u vÃ  Ã¡p dá»¥ng 6 nhÃ³m thuáº­t toÃ¡n tÃ¬m kiáº¿m tiÃªu biá»ƒu trong trÃ­ tuá»‡ nhÃ¢n táº¡o. Tá»« Ä‘Ã³ giÃºp ngÆ°á»i há»c hiá»ƒu rÃµ nhá»¯ng Ä‘áº·c trÆ°ng, cÃ¡ch thá»©c hoáº¡t Ä‘á»™ng vÃ  giá»›i háº¡n cá»§a tá»«ng thuáº­t toÃ¡n. 6 nhÃ³m thuáº­t toÃ¡n chÃ­nh lÃ : 

- NhÃ³m thuáº­t toÃ¡n tÃ¬m kiáº¿m khÃ´ng cÃ³ thÃ´ng tin (Uninformed Search): Breadth-First Search (BFS), Depth-First Search (DFS), Iterative Deepening Search (IDS) vÃ  Uniform Cost Search (UCS). NhÃ³m nÃ y giÃºp Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng giáº£i quyáº¿t bÃ i toÃ¡n khi khÃ´ng cÃ³ thÃ´ng tin Ä‘á»‹nh hÆ°á»›ng, dá»±a hoÃ n toÃ n vÃ o cáº¥u trÃºc cá»§a khÃ´ng gian tráº¡ng thÃ¡i.
- NhÃ³m thuáº­t toÃ¡n tÃ¬m kiáº¿m cÃ³ thÃ´ng tin (Informed Search): Sá»­ dá»¥ng hÃ m heuristic Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u quáº£ tÃ¬m kiáº¿m, bao gá»“m A*, Iterative Deepening A* (IDA*) vÃ  Greedy Best-First Search. NhÃ³m nÃ y káº¿t há»£p thÃ´ng tin Æ°á»›c lÆ°á»£ng Ä‘á»ƒ dáº«n dáº¯t quÃ¡ trÃ¬nh tÃ¬m kiáº¿m nhanh chÃ³ng hÆ¡n.
- NhÃ³m thuáº­t toÃ¡n tÃ¬m kiáº¿m cá»¥c bá»™ (Local Search): Simple Hill Climbing, Steepest-Ascent Hill Climbing, Stochastic Hill Climbing, Simulated Annealing, Beam Search vÃ  Genetic Algorithm. NhÃ³m nÃ y táº­p trung vÃ o viá»‡c cáº£i thiá»‡n lá»i giáº£i hiá»‡n táº¡i dá»±a trÃªn thÃ´ng tin cá»¥c bá»™, khÃ´ng cáº§n lÆ°u toÃ n bá»™ khÃ´ng gian tráº¡ng thÃ¡i, phÃ¹ há»£p vá»›i cÃ¡c bÃ i toÃ¡n cÃ³ khÃ´ng gian lá»›n hoáº·c thiáº¿u tÃ i nguyÃªn.
- NhÃ³m thuáº­t toÃ¡n tÃ¬m kiáº¿m trong mÃ´i trÆ°á»ng phá»©c táº¡p (Searching in Complex Environments): AND-OR Graph Search, Searching with Partial Observability, vÃ  Belief State Search. ÄÃ¢y lÃ  nhÃ³m má»Ÿ rá»™ng á»©ng dá»¥ng sang cÃ¡c bÃ i toÃ¡n cÃ³ tÃ­nh khÃ´ng cháº¯c cháº¯n, thÃ´ng tin khÃ´ng Ä‘áº§y Ä‘á»§, hoáº·c thay Ä‘á»•i theo thá»i gian.
- BÃ i toÃ¡n thá»a mÃ£n rÃ ng buá»™c (Constraint Satisfaction Problems - CSP): Ãp dá»¥ng cÃ¡c thuáº­t toÃ¡n nhÆ° Backtracking, Forward-Checking, vÃ  Min-Conflicts, nháº±m thá»­ nghiá»‡m kháº£ nÄƒng biá»ƒu diá»…n bÃ i toÃ¡n 8-puzzle nhÆ° má»™t há»‡ thá»‘ng rÃ ng buá»™c logic.
- Há»c tÄƒng cÆ°á»ng (Reinforcement Learning): Cá»¥ thá»ƒ lÃ  thuáº­t toÃ¡n Q-learning, cho phÃ©p tÃ¡c nhÃ¢n há»c cÃ¡ch giáº£i bÃ i toÃ¡n thÃ´ng qua quÃ¡ trÃ¬nh tÆ°Æ¡ng tÃ¡c liÃªn tá»¥c vá»›i mÃ´i trÆ°á»ng. NhÃ³m nÃ y Ä‘áº¡i diá»‡n cho hÆ°á»›ng tiáº¿p cáº­n hiá»‡n Ä‘áº¡i, nÆ¡i giáº£i phÃ¡p khÃ´ng Ä‘Æ°á»£c láº­p trÃ¬nh sáºµn mÃ  Ä‘Æ°á»£c há»c thÃ´ng qua kinh nghiá»‡m.

### 2. Ná»™i dung

#### *2.1. NhÃ³m thuáº­t toÃ¡n TÃ¬m kiáº¿m khÃ´ng cÃ³ thÃ´ng tin (Uninformed Search Algorithms)*
CÃ¡c thÃ nh pháº§n chÃ­nh cá»§a bÃ i toÃ¡n tÃ¬m kiáº¿m vÃ  giáº£i phÃ¡p:

- Tráº¡ng thÃ¡i ban Ä‘áº§u(Initial state): Báº£ng 3x3 vá»›i 8 sá»‘ tá»« 1 Ä‘áº¿n 8 vÃ  má»™t Ã´ trá»‘ng (0), Ä‘áº¡i diá»‡n cho tráº¡ng thÃ¡i khá»Ÿi Ä‘áº§u cá»§a bÃ i toÃ¡n.
([[1 2 0], 
  [5 6 3], 
  [4 7 8]
 ]).   
- Tráº¡ng thÃ¡i Ä‘Ã­ch(Goal state): Báº£ng 3x3 vá»›i thá»© tá»± sá»‘ tá»« 1 Ä‘áº¿n 8 vÃ  Ã´ trá»‘ng á»Ÿ vá»‹ trÃ­ cuá»‘i cÃ¹ng: 
([[1 2 3], 
  [4 5 6], 
  [7 8 0]
 ]).                                                                                     
- KhÃ´ng gian tráº¡ng thÃ¡i(State space): Táº­p há»£p táº¥t cáº£ cÃ¡c tráº¡ng thÃ¡i cÃ³ thá»ƒ cÃ³ cá»§a bÃ i toÃ¡n.
- HÃ nh Ä‘á»™ng(Action): Di chuyá»ƒn Ã´ trá»‘ng lÃªn, xuá»‘ng, trÃ¡i, hoáº·c pháº£i Ä‘á»ƒ hoÃ¡n Ä‘á»•i vá»›i Ã´ sá»‘ liá»n ká».
- Chi phÃ­(Cost function): Má»—i bÆ°á»›c di chuyá»ƒn cÃ³ chi phÃ­ báº±ng 1, vÃ¬ bÃ i toÃ¡n Æ°u tiÃªn tÃ¬m Ä‘Æ°á»ng Ä‘i ngáº¯n nháº¥t.
+ Giáº£i phÃ¡p(solution): DÃ£y cÃ¡c tráº¡ng thÃ¡i tá»« tráº¡ng thÃ¡i ban Ä‘áº§u Ä‘áº¿n tráº¡ng thÃ¡i má»¥c tiÃªu, Ä‘Æ°á»£c táº¡o ra bá»Ÿi cÃ¡c thuáº­t toÃ¡n tÃ¬m kiáº¿m khÃ´ng cÃ³ thÃ´ng tin BFS, DFS, UCS, vÃ  IDS.
  
  ![Uninformed Search](Uninformed%20search.gif)
*Nháº­n xÃ©t:*

- BFS (Breadth-First Search): BFS cÃ³ Æ°u Ä‘iá»ƒm ná»•i báº­t lÃ  luÃ´n tÃ¬m Ä‘Æ°á»£c lá»i giáº£i tá»‘i Æ°u vá» sá»‘ bÆ°á»›c di chuyá»ƒn, do nÃ³ khÃ¡m phÃ¡ cÃ¡c tráº¡ng thÃ¡i theo tá»«ng má»©c Ä‘á»™ (level-order), nhÆ°ng nÃ³ cÅ©ng tá»‘n nhiá»u bá»™ nhá»› vÃ¬ pháº£i lÆ°u táº¥t cáº£ tráº¡ng thÃ¡i theo tá»«ng má»©c.
- DFS (Depth-First Search): Tiáº¿t kiá»‡m bá»™ nhá»› do chá»‰ cáº§n lÆ°u má»™t nhÃ¡nh Ä‘Æ°á»ng Ä‘i duy nháº¥t táº¡i má»—i thá»i Ä‘iá»ƒm, nhÆ°ng vÃ¬ váº­y mÃ  nÃ³ dá»… bá»‹ Ä‘i sai hÆ°á»›ng vÃ  khÃ´ng Ä‘áº£m báº£o tÃ¬m Ä‘Æ°á»£c lá»i giáº£i ngáº¯n nháº¥t.
- UCS (Uniform-Cost Search): UCS lÃ  má»Ÿ rá»™ng cá»§a BFS, Ä‘áº£m báº£o lá»i giáº£i tá»‘i Æ°u vÃ  linh hoáº¡t hÆ¡n náº¿u cÃ³ chi phÃ­ khÃ¡c nhau, nhÆ°ng trong 8-puzzle thÃ¬ Ã­t khÃ¡c biá»‡t vÃ  váº«n tá»‘n nhiá»u bá»™ nhá»›.
- IDS (Iterative Deepening Search): Káº¿t há»£p Æ°u Ä‘iá»ƒm cá»§a BFS vÃ  DFS, Ã­t tá»‘n bá»™ nhá»› vÃ  hiá»‡u quáº£ hÆ¡n trong cÃ¡c bÃ i toÃ¡n nhÆ° 8-puzzle.NhÆ°ng thá»i gian thá»±c thi lÃ¢u hÆ¡n vÃ¬ IDS thá»±c hiá»‡n nhiá»u láº§n DFS vá»›i Ä‘á»™ sÃ¢u tÄƒng dáº§n.

#### *2.2. NhÃ³m thuáº­t toÃ¡n TÃ¬m kiáº¿m cÃ³ thÃ´ng tin (Informed Search Algorithms)*
CÃ¡c thÃ nh pháº§n chÃ­nh cá»§a bÃ i toÃ¡n tÃ¬m kiáº¿m vÃ  giáº£i phÃ¡p: 

- Tráº¡ng thÃ¡i ban Ä‘áº§u(Initial state): Báº£ng 3x3 vá»›i 8 sá»‘ tá»« 1 Ä‘áº¿n 8 vÃ  má»™t Ã´ trá»‘ng (0), Ä‘áº¡i diá»‡n cho tráº¡ng thÃ¡i khá»Ÿi Ä‘áº§u cá»§a bÃ i toÃ¡n.
([[8 6 7], 
  [2 5 4], 
  [3 0 1]
 ]).   
- Tráº¡ng thÃ¡i Ä‘Ã­ch(Goal state): Báº£ng 3x3 vá»›i thá»© tá»± sá»‘ tá»« 1 Ä‘áº¿n 8 vÃ  Ã´ trá»‘ng á»Ÿ vá»‹ trÃ­ cuá»‘i cÃ¹ng: 
([[1 2 3], 
  [4 5 6], 
  [7 8 0]
 ]).                                                                                     
- KhÃ´ng gian tráº¡ng thÃ¡i(State space): Táº­p há»£p táº¥t cáº£ cÃ¡c tráº¡ng thÃ¡i cÃ³ thá»ƒ cÃ³ cá»§a bÃ i toÃ¡n.
- HÃ nh Ä‘á»™ng(Action): Di chuyá»ƒn Ã´ trá»‘ng lÃªn, xuá»‘ng, trÃ¡i, hoáº·c pháº£i Ä‘á»ƒ hoÃ¡n Ä‘á»•i vá»›i Ã´ sá»‘ liá»n ká».
- Chi phÃ­(Cost function): Má»—i bÆ°á»›c di chuyá»ƒn cÃ³ chi phÃ­ báº±ng 1, vÃ¬ bÃ i toÃ¡n Æ°u tiÃªn tÃ¬m Ä‘Æ°á»ng Ä‘i ngáº¯n nháº¥t.
+ Giáº£i phÃ¡p(solution): DÃ£y cÃ¡c tráº¡ng thÃ¡i tá»« tráº¡ng thÃ¡i ban Ä‘áº§u Ä‘áº¿n tráº¡ng thÃ¡i má»¥c tiÃªu, Ä‘Æ°á»£c táº¡o ra bá»Ÿi cÃ¡c thuáº­t toÃ¡n tÃ¬m kiáº¿m cÃ³ thÃ´ng tin GBFS, A*, vÃ  IDA*.

  ![Informed Search](Informed%20search.gif)

*Nháº­n xÃ©t:*
- Greedy Best-First Search (GBFS): Cháº¡y nhanh vÃ  khÃ¡m phÃ¡ Ã­t tráº¡ng thÃ¡i nhá» chá»‰ dÃ¹ng giÃ¡ trá»‹ heuristic, nhÆ°ng dá»… Ä‘i sai hÆ°á»›ng vÃ  khÃ´ng Ä‘áº£m báº£o lá»i giáº£i ngáº¯n nháº¥t.
- A*: TÃ¬m Ä‘Æ°á»£c lá»i giáº£i tá»‘i Æ°u nhá» káº¿t há»£p chi phÃ­ Ä‘Ã£ Ä‘i vÃ  heuristic, nhÆ°ng cháº¡y cháº­m hÆ¡n vÃ  tá»‘n nhiá»u bá»™ nhá»› hÆ¡n GBFS.
- IDA* (Iterative Deepening A*): Tiáº¿t kiá»‡m bá»™ nhá»› hÆ¡n A* vÃ  hoáº¡t Ä‘á»™ng tá»‘t trong 8-puzzle, nhÆ°ng cÃ³ thá»ƒ pháº£i láº·p láº¡i nhiá»u láº§n náº¿u heuristic chÆ°a chÃ­nh xÃ¡c, nÃªn tá»‘n thá»i gian hÆ¡n trong má»™t sá»‘ trÆ°á»ng há»£p.

#### *2.3. NhÃ³m thuáº­t toÃ¡n tÃ¬m kiáº¿m cá»¥c bá»™ (Local Search)*
CÃ¡c thÃ nh pháº§n chÃ­nh cá»§a bÃ i toÃ¡n tÃ¬m kiáº¿m vÃ  giáº£i phÃ¡p: 

- Tráº¡ng thÃ¡i ban Ä‘áº§u(Initial state): Báº£ng 3x3 vá»›i 8 sá»‘ tá»« 1 Ä‘áº¿n 8 vÃ  má»™t Ã´ trá»‘ng (0), Ä‘áº¡i diá»‡n cho tráº¡ng thÃ¡i khá»Ÿi Ä‘áº§u cá»§a bÃ i toÃ¡n:
([[1 2 0], 
  [5 6 3], 
  [4 7 8]
 ])
- Tráº¡ng thÃ¡i Ä‘Ã­ch(Goal state): Báº£ng 3x3 vá»›i thá»© tá»± sá»‘ tá»« 1 Ä‘áº¿n 8 vÃ  Ã´ trá»‘ng á»Ÿ vá»‹ trÃ­ cuá»‘i cÃ¹ng: 
([[1 2 3], 
  [4 5 6], 
  [7 8 0]
 ]).                                                                                     
- KhÃ´ng gian tráº¡ng thÃ¡i(State space): Táº­p há»£p táº¥t cáº£ cÃ¡c tráº¡ng thÃ¡i cÃ³ thá»ƒ cÃ³ cá»§a bÃ i toÃ¡n.
- HÃ nh Ä‘á»™ng(Action): Di chuyá»ƒn Ã´ trá»‘ng lÃªn, xuá»‘ng, trÃ¡i, hoáº·c pháº£i Ä‘á»ƒ hoÃ¡n Ä‘á»•i vá»›i Ã´ sá»‘ liá»n ká».
- Chi phÃ­(Cost function): Má»—i bÆ°á»›c di chuyá»ƒn cÃ³ chi phÃ­ báº±ng 1, vÃ¬ bÃ i toÃ¡n Æ°u tiÃªn tÃ¬m Ä‘Æ°á»ng Ä‘i ngáº¯n nháº¥t.
+ Giáº£i phÃ¡p(solution): DÃ£y cÃ¡c tráº¡ng thÃ¡i tá»« tráº¡ng thÃ¡i ban Ä‘áº§u Ä‘áº¿n tráº¡ng thÃ¡i má»¥c tiÃªu, Ä‘Æ°á»£c táº¡o ra bá»Ÿi cÃ¡c thuáº­t toÃ¡n tÃ¬m kiáº¿m cá»¥c bá»™ Simple Hill Climbing, Steepest-Ascent Hill Climbing, Stochastic Hill Climbing, Simulated Annealing, Beam Search vÃ  Genetic Algorithm .

  ![Local Search](Local%20search.gif)
  ![Local](local.png)

*Nháº­n xÃ©t:*
- Simple Hill Climbing: Cháº¡y nhanh nháº¥t vÃ¬ chá»n tráº¡ng thÃ¡i lÃ¢n cáº­n Ä‘áº§u tiÃªn tá»‘t hÆ¡n vÃ  dá»«ng láº¡i náº¿u khÃ´ng cÃ³ tráº¡ng thÃ¡i nÃ o tá»‘t hÆ¡n. NhÆ°ng nÃ³ dá»… bá»‹ káº¹t á»Ÿ Ä‘iá»ƒm tá»‘i Æ°u cá»¥c bá»™ vÃ  khÃ´ng tÃ¬m Ä‘Æ°á»£c lá»i giáº£i tá»‘t nháº¥t vÃ¬ khÃ´ng cÃ³ cÆ¡ cháº¿ thoÃ¡t ra.
- Steepest Ascent Hill Climbing: CÅ©ng ráº¥t nhanh máº·c dÃ¹ pháº£i duyá»‡t háº¿t cÃ¡c lÃ¢n cáº­n, nhÆ°ng thá»i gian thá»±c táº¿ váº«n ráº¥t tháº¥p. KhÃ¡m phÃ¡ nhiá»u tráº¡ng thÃ¡i hÆ¡n Simple Hill Climbing vÃ¬ pháº£i kiá»ƒm tra táº¥t cáº£ cÃ¡c tráº¡ng thÃ¡i lÃ¢n cáº­n Ä‘á»ƒ chá»n cÃ¡i tá»‘t nháº¥t. 
- Stochastic Hill Climbing: Tá»‘c Ä‘á»™ cháº­m hÆ¡n Simple Hill Climbing vÃ  Steepest Ascent Hill Climbing nhÆ°ng váº«n nhanh. Chá»n ngáº«u nhiÃªn má»™t tráº¡ng thÃ¡i lÃ¢n cáº­n tá»‘t hÆ¡n nÃªn khÃ¡m phÃ¡ nhiá»u tráº¡ng thÃ¡i hÆ¡n, phÃ¹ há»£p vá»›i lÃ½ thuyáº¿t.
- Beam Search: áº·c dÃ¹ thÆ°á»ng tá»‘n nhiá»u thá»i gian hÆ¡n Hill Climbing, ta tháº¥y Beam Search cháº¡y ráº¥t nhanh do dá»¯ liá»‡u tráº¡ng thÃ¡i ban Ä‘áº§u cá»§a bÃ i toÃ¡n Ä‘Æ¡n giáº£n.
- Simulated Annealing: Cháº¡y cháº­m hÆ¡n nhÃ³m Hill Climbing. NÃ³ cháº¡y lÃ¢u vÃ¬ cÃ³ cÆ¡ cháº¿ "lÃ m nguá»™i", cháº¥p nháº­n tráº¡ng thÃ¡i tá»‡ hÆ¡n Ä‘á»ƒ thoÃ¡t cá»±c trá»‹ cá»¥c bá»™. Thá»i gian pháº£n Ã¡nh Ä‘Ãºng Ä‘áº·c trÆ°ng nÃ y.
- Genetic Algorithm: Máº·c dÃ¹ cháº­m, nhÆ°ng váº«n nhanh hÆ¡n Simulated Annealing trong biá»ƒu Ä‘á»“ nÃ y, vÃ¬ dá»¯ liá»‡u tráº¡ng thÃ¡i ban Ä‘áº§u cá»§a bÃ i toÃ¡n Ä‘Æ¡n giáº£n. Tuy váº­y, Genetic Algorithm váº«n khÃ¡m phÃ¡ nhiá»u tráº¡ng thÃ¡i hÆ¡n cÃ¡c thuáº­t toÃ¡n khÃ¡c.
#### *2.4. NhÃ³m thuáº­t toÃ¡n tÃ¬m kiáº¿m trong mÃ´i trÆ°á»ng phá»©c táº¡p (Searching in Complex Environments)*
- KhÃ´ng gian tráº¡ng thÃ¡i (State Space): Má»™t báº£ng 3x3 chá»©a cÃ¡c sá»‘ tá»« 0 Ä‘áº¿n 8, trong Ä‘Ã³ 0 Ä‘áº¡i diá»‡n cho Ã´ trá»‘ng. Má»—i tráº¡ng thÃ¡i Ä‘Æ°á»£c biá»ƒu diá»…n dÆ°á»›i dáº¡ng tuple cá»§a cÃ¡c tuple Ä‘á»ƒ Ä‘áº£m báº£o báº¥t biáº¿n (immutability) trong quÃ¡ trÃ¬nh tÃ¬m kiáº¿m.
- Tráº¡ng thÃ¡i má»¥c tiÃªu: CÃ³ thá»ƒ lÃ  má»™t trong nhiá»u tráº¡ng thÃ¡i má»¥c tiÃªu (Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trong goal_states):
[[1, 2, 3], [4, 5, 6], [7, 8, 0]]
[[1, 2, 3], [4, 5, 6], [0, 7, 8]]
[[1, 2, 3], [0, 4, 6], [7, 5, 8]]
- HÃ nh Ä‘á»™ng (Actions): Di chuyá»ƒn Ã´ trá»‘ng lÃªn, xuá»‘ng, trÃ¡i, hoáº·c pháº£i Ä‘á»ƒ hoÃ¡n Ä‘á»•i vá»›i Ã´ sá»‘ liá»n ká».
- HÃ m chi phÃ­ (Cost Function): Má»—i bÆ°á»›c di chuyá»ƒn cÃ³ chi phÃ­ báº±ng 1 (tÆ°Æ¡ng á»©ng vá»›i má»™t láº§n di chuyá»ƒn Ã´ trá»‘ng).
- Táº­p niá»m tin (Belief States): Thay vÃ¬ chá»‰ lÃ m viá»‡c vá»›i má»™t tráº¡ng thÃ¡i duy nháº¥t, bÃ i toÃ¡n sá»­ dá»¥ng táº­p niá»m tin (má»™t táº­p há»£p cÃ¡c tráº¡ng thÃ¡i cÃ³ thá»ƒ xáº£y ra).
- Giáº£i phÃ¡p(solution): TÃ¬m Ä‘Æ°á»ng Ä‘i tá»« táº­p niá»m tin ban Ä‘áº§u Ä‘áº¿n tráº¡ng thÃ¡i má»¥c tiÃªu, trong Ä‘Ã³ Ã­t nháº¥t má»™t tráº¡ng thÃ¡i trong táº­p niá»m tin khá»›p vá»›i má»™t tráº¡ng thÃ¡i má»¥c tiÃªu.

 Belief state search:
 ![Belief state search](Belief%20state%20search.gif)
 Searching with Partial Observability: 
 ![Searching with Partial Observability](Searching%20with%20Partial%20Observability.gif)
 ![and-or](AND-OR%20Graph%20search.gif)
*Nháº­n xÃ©t:*
- Belief State Search: thá»i gian thá»±c thi cao nháº¥t vÃ¬ thuáº­t toÃ¡n pháº£i duy trÃ¬ vÃ  cáº­p nháº­t má»™t táº­p há»£p cÃ¡c tráº¡ng thÃ¡i kháº£ dÄ© trong mÃ´i trÆ°á»ng khÃ´ng xÃ¡c Ä‘á»‹nh.PhÃ¹ há»£p cho cÃ¡c bÃ i toÃ¡n cÃ³ tÃ­nh khÃ´ng xÃ¡c Ä‘á»‹nh cao, nhÆ°ng Ä‘Ã¡nh Ä‘á»•i vá» hiá»‡u nÄƒng.
- Partial Observable Search: Thá»i gian thá»±c thi nhanh hÆ¡n Belief state search, nÃ³ hoáº¡t Ä‘á»™ng tá»‘t trong mÃ´i trÆ°á»ng chá»‰ quan sÃ¡t Ä‘Æ°á»£c má»™t pháº§n tráº¡ng thÃ¡i, nhanh hÆ¡n vÃ¬ giá»›i háº¡n pháº¡m vi tÃ¬m kiáº¿m á»Ÿ má»©c Ä‘á»™ phÃ¹ há»£p vá»›i thÃ´ng tin hiá»‡n cÃ³.
- AND-OR Graph Search: Thá»i gian thá»±c thi nhanh nháº¥t, thuáº­t toÃ¡n nÃ y phÃ¹ há»£p nháº¥t khi bÃ i toÃ¡n cÃ³ cáº¥u trÃºc phÃ¢n nhÃ¡nh rÃµ rÃ ng vÃ  cÃ³ thá»ƒ mÃ´ hÃ¬nh hÃ³a cÃ¡c Ä‘iá»u kiá»‡n theo logic AND vÃ  OR.
#### *2.5. BÃ i toÃ¡n thá»a mÃ£n rÃ ng buá»™c (Constraint Satisfaction Problems (CSPs))*
CÃ¡c thÃ nh pháº§n chÃ­nh cá»§a bÃ i toÃ¡n tÃ¬m kiáº¿m vÃ  giáº£i phÃ¡p: 

- Tráº¡ng thÃ¡i ban Ä‘áº§u(Initial state): Báº£ng 3x3 chá»‰ lÃ  Ã´ trá»‘ng (0), Ä‘áº¡i diá»‡n cho tráº¡ng thÃ¡i khá»Ÿi Ä‘áº§u cá»§a bÃ i toÃ¡n:
([[0 0 0], 
  [0 0 0], 
  [0 0 0]
 ])
- Tráº¡ng thÃ¡i Ä‘Ã­ch(Goal state): Báº£ng 3x3 vá»›i thá»© tá»± sá»‘ tá»« 1 Ä‘áº¿n 8 vÃ  Ã´ trá»‘ng á»Ÿ vá»‹ trÃ­ cuá»‘i cÃ¹ng: 
([[1 2 3], 
  [4 5 6], 
  [7 8 0]
 ]).                                                                                     
- KhÃ´ng gian tráº¡ng thÃ¡i(State space): Táº­p há»£p táº¥t cáº£ cÃ¡c tráº¡ng thÃ¡i cÃ³ thá»ƒ cÃ³ cá»§a bÃ i toÃ¡n.
- RÃ ng buá»™c: HÃ m is_valid_assignment Ä‘áº£m báº£o ráº±ng má»—i tráº¡ng thÃ¡i Ä‘Æ°á»£c táº¡o ra trong quÃ¡ trÃ¬nh tÃ¬m kiáº¿m thá»a mÃ£n cÃ¡c rÃ ng buá»™c cá»§a bÃ i toÃ¡n, nhÆ° má»—i sá»‘ chá»‰ xuáº¥t hiá»‡n má»™t láº§n vÃ  cÃ¡c sá»‘ liá»n ká» pháº£i thá»a mÃ£n Ä‘iá»u kiá»‡n thá»© tá»± (theo hÃ ng hoáº·c cá»™t).
- HÃ nh Ä‘á»™ng(Action): Äiá»n sá»‘ vÃ o Ã´ trá»‘ng hoáº·c di chuyá»ƒn Ã´ trá»‘ng lÃªn, xuá»‘ng, trÃ¡i, hoáº·c pháº£i Ä‘á»ƒ hoÃ¡n Ä‘á»•i vá»›i Ã´ sá»‘ liá»n ká».
+ Giáº£i phÃ¡p(solution): Giáº£i phÃ¡p lÃ  má»™t chuá»—i cÃ¡c tráº¡ng thÃ¡i (Ä‘Æ°á»ng Ä‘i) tá»« tráº¡ng thÃ¡i ban Ä‘áº§u Ä‘áº¿n tráº¡ng thÃ¡i Ä‘Ã­ch, sao cho má»—i bÆ°á»›c chuyá»ƒn Ä‘á»•i giá»¯a cÃ¡c tráº¡ng thÃ¡i lÃ  há»£p lá»‡ (thÃ´ng qua má»™t hÃ nh Ä‘á»™ng).Backtracking Search vÃ  Backtracking with Forward Checking tÃ¬m Ä‘Æ°á»ng Ä‘i báº±ng cÃ¡ch thá»­ táº¥t cáº£ cÃ¡c giÃ¡ trá»‹ cÃ³ thá»ƒ (0 Ä‘áº¿n 8) cho tá»«ng Ã´, Ä‘áº£m báº£o thá»a mÃ£n cÃ¡c rÃ ng buá»™c. CÃ²n Min-Conflicts tÃ¬m kiáº¿m cá»¥c bá»™, báº¯t Ä‘áº§u tá»« má»™t tráº¡ng thÃ¡i ngáº«u nhiÃªn vÃ  láº·p láº¡i viá»‡c di chuyá»ƒn Ã´ trá»‘ng Ä‘áº¿n cÃ¡c Ã´ liá»n ká» Ä‘á»ƒ giáº£m thiá»ƒu xung Ä‘á»™t.
  ![CSPs](CSPs.gif)

*Nháº­n xÃ©t:*
- Backtracking: Thuáº­t toÃ¡n cÆ¡ báº£n, kiá»ƒm tra rÃ ng buá»™c sau khi gÃ¡n giÃ¡ trá»‹. KhÃ´ng cÃ³ cÆ¡ cháº¿ loáº¡i trá»« trÆ°á»›c nÃªn pháº£i thá»­ nhiá»u kháº£ nÄƒng dáº«n Ä‘áº¿n thá»i gian thá»±c thi lÃ¢u.
- Backtracking with Forward Checking: Nhanh hÆ¡n Backtracking vÃ¬ loáº¡i bá» trÆ°á»›c nhá»¯ng giÃ¡ trá»‹ khÃ´ng há»£p lá»‡. Viá»‡c kiá»ƒm tra rÃ ng buá»™c sá»›m giÃºp giáº£m sá»‘ nhÃ¡nh cáº§n xÃ©t vÃ¬ tháº¿ thá»i gian thá»±c thi nhanh hÆ¡n.
- Min-Conflicts: LÃ  thuáº­t toÃ¡n heuristic nÃªn khÃ´ng duyá»‡t toÃ n bá»™ khÃ´ng gian tÃ¬m kiáº¿m. Báº¯t Ä‘áº§u tá»« lá»i giáº£i ngáº«u nhiÃªn vÃ  sá»­a dáº§n mÃ¢u thuáº«n, ráº¥t nhanh vá»›i bÃ i toÃ¡n phÃ¹ há»£p, Ä‘áº·c biá»‡t lÃ  cÃ¡c bÃ i toÃ¡n dá»… sá»­a lá»—i cá»¥c bá»™.
#### *2.6 Há»c tÄƒng cÆ°á»ng (Reinforcement Learning)*
CÃ¡c thÃ nh pháº§n chÃ­nh cá»§a bÃ i toÃ¡n tÃ¬m kiáº¿m vÃ  giáº£i phÃ¡p

- Tráº¡ng thÃ¡i ban Ä‘áº§u(Initial state): Báº£ng 3x3 vá»›i 8 sá»‘ tá»« 1 Ä‘áº¿n 8 vÃ  má»™t Ã´ trá»‘ng (0), Ä‘áº¡i diá»‡n cho tráº¡ng thÃ¡i khá»Ÿi Ä‘áº§u cá»§a bÃ i toÃ¡n:
([[1 2 0], 
  [5 6 3], 
  [4 7 8]
 ])
- Tráº¡ng thÃ¡i Ä‘Ã­ch(Goal state): Báº£ng 3x3 vá»›i thá»© tá»± sá»‘ tá»« 1 Ä‘áº¿n 8 vÃ  Ã´ trá»‘ng á»Ÿ vá»‹ trÃ­ cuá»‘i cÃ¹ng: 
([[1 2 3], 
  [4 5 6], 
  [7 8 0]
 ]).                                                                                     
- KhÃ´ng gian tráº¡ng thÃ¡i(State space): Táº­p há»£p táº¥t cáº£ cÃ¡c cáº¥u hÃ¬nh cÃ³ thá»ƒ cá»§a lÆ°á»›i 3x3, Ä‘Æ°á»£c táº¡o ra báº±ng cÃ¡ch hoÃ¡n Ä‘á»•i Ã´ trá»‘ng vá»›i cÃ¡c Ã´ liá»n ká» há»£p lá»‡. Thuáº­t toÃ¡n Q-Learning há»c chÃ­nh sÃ¡ch tá»‘i Æ°u thÃ´ng qua viá»‡c khÃ¡m phÃ¡ khÃ´ng gian tráº¡ng thÃ¡i nÃ y.
- HÃ nh Ä‘á»™ng(Action): Di chuyá»ƒn Ã´ trá»‘ng lÃªn, xuá»‘ng, trÃ¡i, hoáº·c pháº£i Ä‘á»ƒ hoÃ¡n Ä‘á»•i vá»›i Ã´ sá»‘ liá»n ká».
- Chi phÃ­(Cost function): Trong thuáº­t toÃ¡n nÃ y chi phÃ­ Ä‘Æ°á»£c hiá»ƒu cÃ¡ch khÃ¡c lÃ  pháº§n thÆ°á»Ÿng. Má»—i bÆ°á»›c di chuyá»ƒn Ä‘Æ°á»£c gÃ¡n má»™t pháº§n thÆ°á»Ÿng Ã¢m nhá», vÃ¬ bÃ i toÃ¡n táº­p trung vÃ o tá»‘i Æ°u hÃ³a tá»•ng pháº§n thÆ°á»Ÿng tÃ­ch lÅ©y Ä‘á»ƒ tÃ¬m Ä‘Æ°á»ng Ä‘i tá»« tráº¡ng thÃ¡i ban Ä‘áº§u Ä‘áº¿n tráº¡ng thÃ¡i má»¥c tiÃªu. Agent nháº­n pháº§n thÆ°á»Ÿng lá»›n khi Ä‘áº¡t tráº¡ng thÃ¡i má»¥c tiÃªu.
+ Giáº£i phÃ¡p(solution): Má»™t dÃ£y cÃ¡c tráº¡ng thÃ¡i tá»« tráº¡ng thÃ¡i ban Ä‘áº§u Ä‘áº¿n tráº¡ng thÃ¡i má»¥c tiÃªu, Ä‘Æ°á»£c táº¡o ra bá»Ÿi thuáº­t toÃ¡n Q-Learning. Thuáº­t toÃ¡n há»c chÃ­nh sÃ¡ch tá»‘i Æ°u báº±ng cÃ¡ch cáº­p nháº­t báº£ng Q (Q-table) dá»±a trÃªn pháº§n thÆ°á»Ÿng, sau Ä‘Ã³ trÃ­ch xuáº¥t Ä‘Æ°á»ng Ä‘i tá»« báº£ng Q Ä‘Ã£ há»c.

 ![Qlearning](Q_learning.gif)

*Nháº­n xÃ©t:*
Q-Learning: Thuáº­t toÃ¡n sá»­ dá»¥ng chiáº¿n lÆ°á»£c Epsilon-Greedy Ä‘á»ƒ cÃ¢n báº±ng giá»¯a khÃ¡m phÃ¡ vÃ  khai thÃ¡c. Sá»‘ tráº¡ng thÃ¡i khÃ¡m phÃ¡ cao do Q-Learning cáº§n thÄƒm nhiá»u tráº¡ng thÃ¡i trong quÃ¡ trÃ¬nh há»c Ä‘á»ƒ xÃ¢y dá»±ng chÃ­nh sÃ¡ch tá»‘i Æ°u. Thá»i gian cháº¡y tÆ°Æ¡ng Ä‘á»‘i cao vÃ¬ sá»‘ lÆ°á»£ng tráº¡ng thÃ¡i lá»›n vÃ  chi phÃ­ tÃ­nh toÃ¡n má»—i bÆ°á»›c bao gá»“m cáº­p nháº­t Q-value, tÃ­nh pháº§n thÆ°á»Ÿng, vÃ  kiá»ƒm tra tráº¡ng thÃ¡i lÃ¢n cáº­n. Tuy nhiÃªn, Q-Learning Ä‘áº£m báº£o há»™i tá»¥ vá» chÃ­nh sÃ¡ch tá»‘i Æ°u náº¿u cÃ³ Ä‘á»§ thá»i gian há»c, phÃ¹ há»£p khi cáº§n há»c chÃ­nh sÃ¡ch dÃ i háº¡n trong mÃ´i trÆ°á»ng khÃ´ng xÃ¡c Ä‘á»‹nh.


ğŸ”— ----------------------------------------

SVTH: BÃ¹i Quá»‘c Háº­u
